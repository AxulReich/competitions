{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import xgboost as xgb\n",
    "\n",
    "# from rmse import rmse "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1879842, 8) (664524, 8) (1879842, 1) (664524,)\n"
     ]
    }
   ],
   "source": [
    "%run load_encoded.ipynb\n",
    "\n",
    "print(X.shape, X_test.shape, y.shape, ids.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## run `xgboost`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dtrain = xgb.DMatrix(X, y, missing = 0.0)\n",
    "dtest = xgb.DMatrix(X_test)\n",
    "\n",
    "n_trees = 900"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "XGBoostError",
     "evalue": "sklearn needs to be installed in order to use this module",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mXGBoostError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-f6b0596a4600>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m                        \u001b[0mmax_depth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                         \u001b[0mlearning_rate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m                        colsample_bytree = 0.75)\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.4/dist-packages/xgboost-0.6-py3.4.egg/xgboost/sklearn.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, max_depth, learning_rate, n_estimators, silent, objective, nthread, gamma, min_child_weight, max_delta_step, subsample, colsample_bytree, colsample_bylevel, reg_alpha, reg_lambda, scale_pos_weight, base_score, seed, missing)\u001b[0m\n\u001b[1;32m    119\u001b[0m                  base_score=0.5, seed=0, missing=None):\n\u001b[1;32m    120\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mSKLEARN_INSTALLED\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mXGBoostError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'sklearn needs to be installed in order to use this module'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_depth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax_depth\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearning_rate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mXGBoostError\u001b[0m: sklearn needs to be installed in order to use this module"
     ]
    }
   ],
   "source": [
    "est = xgb.XGBRegressor(n_estimators = n_trees, \n",
    "                       max_depth = 10, \n",
    "                        learning_rate = 0.2, \n",
    "                       colsample_bytree = 0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 35min 54s, sys: 16 s, total: 36min 10s\n",
      "Wall time: 36min 26s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, colsample_bylevel=1, colsample_bytree=0.75,\n",
       "       gamma=0, learning_rate=0.2, max_delta_step=0, max_depth=10,\n",
       "       min_child_weight=1, missing=None, n_estimators=1000, nthread=-1,\n",
       "       objective='reg:linear', reg_alpha=0, reg_lambda=1,\n",
       "       scale_pos_weight=1, seed=0, silent=True, subsample=1)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "est.fit(X, y, eval_metric = 'rmse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4min 10s, sys: 2.04 s, total: 4min 12s\n",
      "Wall time: 4min 13s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "pred = est.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "# pred_train = est.predict(X)\n",
    "\n",
    "# rmse_train = '{0:4f}'.format(rmse(pred_train, y))\n",
    "# print(rmse_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `n_estimators = 500, max_depth = 10`: 0.013363 (**lb 3,93942%**)\n",
    "* `n_estimators = 1000, max_depth = 10`: 0.010008 (**lb 3,84641%**)\n",
    "* `n_estimators = 1000, max_depth = 10, learning_rate = 0.2`: **lb 3,83051%**\n",
    "* `n_estimators = 1000, max_depth = 10, learning_rate = 0.2, colsample_bytree = 0.75`: xxx (**lb 3,89680%**)\n",
    "* `n_estimators = 200, max_depth = 10`: **lb 4,37111%**\n",
    "* `n_estimators = 200, max_depth = 10, learning_rate = 0.2, colsample_bytree = 0.75`: xxx (**lb 4,27724%**)\n",
    "* `n_estimators = 1000, max_depth = 10, learning_rate = 0.2, colsample_bytree = 0.8`: lb 3,89759%\n",
    "* `xgb, 1000 trees, {'learning_rate': 0.2, 'max_depth': 10}`: lb 3,83051%\n",
    "* **`xgb, 900 trees, {'learning_rate': 0.2, 'max_depth': 10}`: lb 3,80539%**\n",
    "* `xgb, 800 trees, {'learning_rate': 0.2, 'max_depth': 10}`: lb 3,80653%\n",
    "* `xgb, 900 trees, {'learning_rate': 0.2, 'max_depth': 10, colsample_bytree=0.8}`: lb 3,90856%. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## make submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cible = ['{0:.1f}'.format(p) for p in pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving to submissions/xgb_1000trees_0510_0033.csv...\n"
     ]
    }
   ],
   "source": [
    "datename = datetime.now().strftime(format = '%d%m_%H%M')\n",
    "folder = 'submissions'\n",
    "# filename = folder + '/' + 'xgb_' + rmse_train + '_' + str(n_trees) + 'trees_' + datename + '.csv'\n",
    "filename = folder + '/' + 'xgb_' + str(n_trees) + 'trees_' + datename + '.csv'\n",
    "# filename = folder + '/' + 'xgb_' + datename + '.csv'\n",
    "print('saving to %s...' % filename)\n",
    "\n",
    "pd.DataFrame(cible, ids).to_csv(filename, sep=';', index_label = 'id', header = ['cible'], float_format = '{.1f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
